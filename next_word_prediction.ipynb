{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a74a094",
   "metadata": {},
   "source": [
    "# Next Word Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6616f57",
   "metadata": {},
   "source": [
    "#### Steps to build the next word recommender system:\n",
    "\n",
    "1. Loading and exploring the dataset\n",
    "2. Creating N-grams of the dialogue\n",
    "3. Building the N-gram Language Model\n",
    "4. Predicting the next word using N-gram Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fdc278",
   "metadata": {},
   "source": [
    "### 1. Loading and exploring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20e48399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0175344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_number</th>\n",
       "      <th>sentence_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ASIAN EXPORTERS FEAR DAMAGE FROM U . S .- JAPA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>They told Reuter correspondents in Asian capit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>But some exporters said that while the conflic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The U . S . Has said it will impose 300 mln dl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Unofficial Japanese estimates put the impact o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_number                                      sentence_text\n",
       "0                0  ASIAN EXPORTERS FEAR DAMAGE FROM U . S .- JAPA...\n",
       "1                1  They told Reuter correspondents in Asian capit...\n",
       "2                2  But some exporters said that while the conflic...\n",
       "3                3  The U . S . Has said it will impose 300 mln dl...\n",
       "4                4  Unofficial Japanese estimates put the impact o..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading dataset\n",
    "data = pd.read_csv(r\"C:\\Users\\TheWhiteWolf\\NLP\\Module1\\Projects\\Next_Word_Project\\Next_Word\\sample_reuters_dataset.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e7bf849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ASIAN EXPORTERS FEAR DAMAGE FROM U . S .- JAPA...\n",
       "1    They told Reuter correspondents in Asian capit...\n",
       "2    But some exporters said that while the conflic...\n",
       "3    The U . S . Has said it will impose 300 mln dl...\n",
       "4    Unofficial Japanese estimates put the impact o...\n",
       "Name: sentence_text, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentence_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80e7d6c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of text sequences\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a4e54c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75a41f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to preprocess (text cleaning)\n",
    "def clean(text):\n",
    "    # remove everything except alphabets, ' and white spaces\n",
    "    text = re.sub(\"[^a-zA-Z' ]\", \"\", text)\n",
    "    # convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    text = re.sub(\" '\", \"'\", text)\n",
    "    text = re.sub(\"' \", \"'\", text)\n",
    "    text = re.sub(\"u  s\", \"us\", text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f851c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing speeches\n",
    "dialogs_clean = data['sentence_text'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "677ac977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dialogs_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b9eac24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"asian exporters fear damage from us  japan rift mounting trade friction between the us  and japan has raised fears among many of asia's exporting nations that the row could inflict far  reaching economic damage  businessmen and officials said \""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogs_clean[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb810be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"usda estimates european community crops the us  agriculture department forecast the european community's    wheat crop at    mln tonnes  vs    mln tonnes last month \",\n",
       " 'spotty germination and winterkill in those fields averaged  to  pct  it said ',\n",
       " ' however  that is the normal wording and we expect the hague court to refer questions on the interpretation and application of the levy to the european court of justice in luxembourg  pex added ',\n",
       " 'garo armen  an analyst with dean witter reynolds  said chemical makers have also benefitted by increasing demand for plastics as prices become more competitive with aluminum  wood and steel products ',\n",
       " 'arrangements for financing have not yet been made and there can be no assurance that any financing will be received  hmo said ',\n",
       " \"officials said the complementary character of the two firms'operations was a further reason \",\n",
       " 'european markets react quietly to g   communique european currency markets reacted quietly to the g   communique  with comments from bankers and dealers ranging from disappointment that it was not more concrete to surprise that the markets should have expected so much ',\n",
       " 'sosnoff said later in a statement that the    mln shares he is now seeking  together with the      shares he owns  would give him a    pct interest on a fully diluted basis ',\n",
       " 'cotton  mln bales                            start stcks             production             imports             mill use             exports             end stocks             note  imports and exports may not balance due to cotton in transit and reporting discrepancies in some countries ',\n",
       " 'consensus seen on tin pact extension the quarterly session of the international tin council  itc  continued without formal agreement on an extension of the sixth international tin agreement  ita  but delegates said it was apparent there was a general consensus the agreement should be prolonged ']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(list(dialogs_clean), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dec4bb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the vocabulary\n",
    "# get list of all the words\n",
    "all_words = \" \".join(dialogs_clean).split()\n",
    "\n",
    "words_dict = {}\n",
    "\n",
    "# add word-count pair to the dictionary\n",
    "for word in all_words:   \n",
    "    # check if the word is already in dictionary \n",
    "    if word in words_dict:\n",
    "        # increment count of word by 1 \n",
    "        words_dict[word] = words_dict[word] + 1\n",
    "    else:\n",
    "        # add the word to dictionary with count 1 \n",
    "        words_dict[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "840b3557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('asian', 13)\n",
      "('exporters', 49)\n",
      "('fear', 8)\n",
      "('damage', 29)\n",
      "('from', 1369)\n"
     ]
    }
   ],
   "source": [
    "# word dictionary\n",
    "for x in list(words_dict.items())[0:5]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "de4f6197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare a dataframe\n",
    "words_df = pd.DataFrame({'word':list(words_dict.keys()), 'count':list(words_dict.values())})\n",
    "\n",
    "# sort words by their count in increasing order\n",
    "words_df = words_df.sort_values(by = ['count'])\n",
    "\n",
    "# reset dataframe index\n",
    "words_df.reset_index(inplace = True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "122d4979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>compute</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baggage</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>conergic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>foster's</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>improper</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word  count\n",
       "0   compute      1\n",
       "1   baggage      1\n",
       "2  conergic      1\n",
       "3  foster's      1\n",
       "4  improper      1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# words with least frequency\n",
    "words_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aede4258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13165</th>\n",
       "      <td>said</td>\n",
       "      <td>4649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13166</th>\n",
       "      <td>in</td>\n",
       "      <td>5070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13167</th>\n",
       "      <td>to</td>\n",
       "      <td>6337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13168</th>\n",
       "      <td>of</td>\n",
       "      <td>6670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13169</th>\n",
       "      <td>the</td>\n",
       "      <td>12496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word  count\n",
       "13165  said   4649\n",
       "13166    in   5070\n",
       "13167    to   6337\n",
       "13168    of   6670\n",
       "13169   the  12496"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# words with highest frequency\n",
    "words_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26cbc93c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13170"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocabulary size\n",
    "len(words_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd62f73",
   "metadata": {},
   "source": [
    "### 2. Creating N-grams of the dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e832d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asian exporters fear damage from us  japan rif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>they told reuter correspondents in asian capit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>but some exporters said that while the conflic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the us  has said it will impose  mln dlrs of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unofficial japanese estimates put the impact o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>we wouldn't be able to do business  said a sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>if the tariffs remain in place for any length...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>in taiwan  businessmen and officials are also ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>we are aware of the seriousness of the us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>threat against japan because it serves as a wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>taiwan had a trade trade surplus of    billion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>the surplus helped swell taiwan's foreign exch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>we must quickly open our markets  remove trad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>retaliation  said paul sheen  chairman of text...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>a senior official of south korea's trade promo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>last year south korea had a trade surplus of  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>in malaysia  trade officers and businessmen sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>in hong kong  where newspapers have alleged ja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>but other businessmen said such a short  term ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>that is a very short  term view  said lawrenc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentences\n",
       "0   asian exporters fear damage from us  japan rif...\n",
       "1   they told reuter correspondents in asian capit...\n",
       "2   but some exporters said that while the conflic...\n",
       "3   the us  has said it will impose  mln dlrs of t...\n",
       "4   unofficial japanese estimates put the impact o...\n",
       "5    we wouldn't be able to do business  said a sp...\n",
       "6    if the tariffs remain in place for any length...\n",
       "7   in taiwan  businessmen and officials are also ...\n",
       "8          we are aware of the seriousness of the us \n",
       "9   threat against japan because it serves as a wa...\n",
       "10  taiwan had a trade trade surplus of    billion...\n",
       "11  the surplus helped swell taiwan's foreign exch...\n",
       "12   we must quickly open our markets  remove trad...\n",
       "13  retaliation  said paul sheen  chairman of text...\n",
       "14  a senior official of south korea's trade promo...\n",
       "15  last year south korea had a trade surplus of  ...\n",
       "16  in malaysia  trade officers and businessmen sa...\n",
       "17  in hong kong  where newspapers have alleged ja...\n",
       "18  but other businessmen said such a short  term ...\n",
       "19   that is a very short  term view  said lawrenc..."
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating an empty dataframe\n",
    "dataset = pd.DataFrame()\n",
    "\n",
    "# adding cleaned sentences in the dataframe\n",
    "dataset['Sentences'] = dialogs_clean\n",
    "\n",
    "# first 20 cleaned sentences\n",
    "dataset.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ffbe442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asian',\n",
       " 'exporters',\n",
       " 'fear',\n",
       " 'damage',\n",
       " 'from',\n",
       " 'us',\n",
       " 'japan',\n",
       " 'rift',\n",
       " 'mounting',\n",
       " 'trade',\n",
       " 'friction',\n",
       " 'between',\n",
       " 'the',\n",
       " 'us',\n",
       " 'and',\n",
       " 'japan',\n",
       " 'has',\n",
       " 'raised',\n",
       " 'fears',\n",
       " 'among',\n",
       " 'many',\n",
       " 'of',\n",
       " \"asia's\",\n",
       " 'exporting',\n",
       " 'nations',\n",
       " 'that',\n",
       " 'the',\n",
       " 'row',\n",
       " 'could',\n",
       " 'inflict',\n",
       " 'far',\n",
       " 'reaching',\n",
       " 'economic',\n",
       " 'damage',\n",
       " 'businessmen',\n",
       " 'and',\n",
       " 'officials',\n",
       " 'said']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using .split() to get tokens from the sentence\n",
    "dataset['Sentences'][0].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8e23df69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create unigrams\n",
    "# taking a sentence as input\n",
    "def create_unigram(sentence):\n",
    "    # creating tokens from the sentence\n",
    "    tokens = sentence.split()\n",
    "    # empty list to store the unigrams\n",
    "    unigram_list = []\n",
    "    # number of unigrams is equal to the number of tokens in the sentence\n",
    "    for i in range(len(tokens)):\n",
    "        # appending each unigram in the list\n",
    "        unigram_list.append(tokens[i:i+1])\n",
    "    # returning the unigram list for a sentence    \n",
    "    return unigram_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "14eba198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create bigrams\n",
    "def create_bigram(sentence):\n",
    "    tokens = sentence.split()\n",
    "    bigram_list = []\n",
    "    # number of bigrams is one less than the number of tokens in the sentence\n",
    "    for i in range(len(tokens)-1):\n",
    "        bigram_list.append(tokens[i:i+2])\n",
    "    return bigram_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed819570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create trigrams\n",
    "def create_trigram(sentence):\n",
    "    tokens = sentence.split()\n",
    "    trigram_list = []\n",
    "    # number of trigrams is two less than the number of tokens in the sentence\n",
    "    for i in range(len(tokens)-2):\n",
    "        trigram_list.append(tokens[i:i+3])\n",
    "    return trigram_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4bf9aa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating unigrams for all the sentences in the dataset \n",
    "final_unigram = []\n",
    "# for each sentence\n",
    "for i in range(dataset.shape[0]):\n",
    "    # using the defined unigram function to create unigrams\n",
    "    final_unigram.append(create_unigram(dataset['Sentences'][i]))\n",
    "\n",
    "# adding the unigram in a seperate column in the dataset\n",
    "dataset['unigram'] = final_unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4ba2bc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating bigrams for all the sentences in the dataset\n",
    "final_bigram = []\n",
    "for i in range(dataset.shape[0]):\n",
    "    final_bigram.append(create_bigram(dataset['Sentences'][i]))\n",
    "\n",
    "dataset['bigram'] = final_bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8eb18ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating trigrams for all the sentences in the dataset\n",
    "final_trigram = []\n",
    "for i in range(dataset.shape[0]):\n",
    "    final_trigram.append(create_trigram(dataset['Sentences'][i]))\n",
    "\n",
    "dataset['trigram'] = final_trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "516e0177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>unigram</th>\n",
       "      <th>bigram</th>\n",
       "      <th>trigram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asian exporters fear damage from us  japan rif...</td>\n",
       "      <td>[[asian], [exporters], [fear], [damage], [from...</td>\n",
       "      <td>[[asian, exporters], [exporters, fear], [fear,...</td>\n",
       "      <td>[[asian, exporters, fear], [exporters, fear, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>they told reuter correspondents in asian capit...</td>\n",
       "      <td>[[they], [told], [reuter], [correspondents], [...</td>\n",
       "      <td>[[they, told], [told, reuter], [reuter, corres...</td>\n",
       "      <td>[[they, told, reuter], [told, reuter, correspo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>but some exporters said that while the conflic...</td>\n",
       "      <td>[[but], [some], [exporters], [said], [that], [...</td>\n",
       "      <td>[[but, some], [some, exporters], [exporters, s...</td>\n",
       "      <td>[[but, some, exporters], [some, exporters, sai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the us  has said it will impose  mln dlrs of t...</td>\n",
       "      <td>[[the], [us], [has], [said], [it], [will], [im...</td>\n",
       "      <td>[[the, us], [us, has], [has, said], [said, it]...</td>\n",
       "      <td>[[the, us, has], [us, has, said], [has, said, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unofficial japanese estimates put the impact o...</td>\n",
       "      <td>[[unofficial], [japanese], [estimates], [put],...</td>\n",
       "      <td>[[unofficial, japanese], [japanese, estimates]...</td>\n",
       "      <td>[[unofficial, japanese, estimates], [japanese,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>we wouldn't be able to do business  said a sp...</td>\n",
       "      <td>[[we], [wouldn't], [be], [able], [to], [do], [...</td>\n",
       "      <td>[[we, wouldn't], [wouldn't, be], [be, able], [...</td>\n",
       "      <td>[[we, wouldn't, be], [wouldn't, be, able], [be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>if the tariffs remain in place for any length...</td>\n",
       "      <td>[[if], [the], [tariffs], [remain], [in], [plac...</td>\n",
       "      <td>[[if, the], [the, tariffs], [tariffs, remain],...</td>\n",
       "      <td>[[if, the, tariffs], [the, tariffs, remain], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>in taiwan  businessmen and officials are also ...</td>\n",
       "      <td>[[in], [taiwan], [businessmen], [and], [offici...</td>\n",
       "      <td>[[in, taiwan], [taiwan, businessmen], [busines...</td>\n",
       "      <td>[[in, taiwan, businessmen], [taiwan, businessm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>we are aware of the seriousness of the us</td>\n",
       "      <td>[[we], [are], [aware], [of], [the], [seriousne...</td>\n",
       "      <td>[[we, are], [are, aware], [aware, of], [of, th...</td>\n",
       "      <td>[[we, are, aware], [are, aware, of], [aware, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>threat against japan because it serves as a wa...</td>\n",
       "      <td>[[threat], [against], [japan], [because], [it]...</td>\n",
       "      <td>[[threat, against], [against, japan], [japan, ...</td>\n",
       "      <td>[[threat, against, japan], [against, japan, be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>taiwan had a trade trade surplus of    billion...</td>\n",
       "      <td>[[taiwan], [had], [a], [trade], [trade], [surp...</td>\n",
       "      <td>[[taiwan, had], [had, a], [a, trade], [trade, ...</td>\n",
       "      <td>[[taiwan, had, a], [had, a, trade], [a, trade,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>the surplus helped swell taiwan's foreign exch...</td>\n",
       "      <td>[[the], [surplus], [helped], [swell], [taiwan'...</td>\n",
       "      <td>[[the, surplus], [surplus, helped], [helped, s...</td>\n",
       "      <td>[[the, surplus, helped], [surplus, helped, swe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>we must quickly open our markets  remove trad...</td>\n",
       "      <td>[[we], [must], [quickly], [open], [our], [mark...</td>\n",
       "      <td>[[we, must], [must, quickly], [quickly, open],...</td>\n",
       "      <td>[[we, must, quickly], [must, quickly, open], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>retaliation  said paul sheen  chairman of text...</td>\n",
       "      <td>[[retaliation], [said], [paul], [sheen], [chai...</td>\n",
       "      <td>[[retaliation, said], [said, paul], [paul, she...</td>\n",
       "      <td>[[retaliation, said, paul], [said, paul, sheen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>a senior official of south korea's trade promo...</td>\n",
       "      <td>[[a], [senior], [official], [of], [south], [ko...</td>\n",
       "      <td>[[a, senior], [senior, official], [official, o...</td>\n",
       "      <td>[[a, senior, official], [senior, official, of]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>last year south korea had a trade surplus of  ...</td>\n",
       "      <td>[[last], [year], [south], [korea], [had], [a],...</td>\n",
       "      <td>[[last, year], [year, south], [south, korea], ...</td>\n",
       "      <td>[[last, year, south], [year, south, korea], [s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>in malaysia  trade officers and businessmen sa...</td>\n",
       "      <td>[[in], [malaysia], [trade], [officers], [and],...</td>\n",
       "      <td>[[in, malaysia], [malaysia, trade], [trade, of...</td>\n",
       "      <td>[[in, malaysia, trade], [malaysia, trade, offi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>in hong kong  where newspapers have alleged ja...</td>\n",
       "      <td>[[in], [hong], [kong], [where], [newspapers], ...</td>\n",
       "      <td>[[in, hong], [hong, kong], [kong, where], [whe...</td>\n",
       "      <td>[[in, hong, kong], [hong, kong, where], [kong,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>but other businessmen said such a short  term ...</td>\n",
       "      <td>[[but], [other], [businessmen], [said], [such]...</td>\n",
       "      <td>[[but, other], [other, businessmen], [business...</td>\n",
       "      <td>[[but, other, businessmen], [other, businessme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>that is a very short  term view  said lawrenc...</td>\n",
       "      <td>[[that], [is], [a], [very], [short], [term], [...</td>\n",
       "      <td>[[that, is], [is, a], [a, very], [very, short]...</td>\n",
       "      <td>[[that, is, a], [is, a, very], [a, very, short...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentences  \\\n",
       "0   asian exporters fear damage from us  japan rif...   \n",
       "1   they told reuter correspondents in asian capit...   \n",
       "2   but some exporters said that while the conflic...   \n",
       "3   the us  has said it will impose  mln dlrs of t...   \n",
       "4   unofficial japanese estimates put the impact o...   \n",
       "5    we wouldn't be able to do business  said a sp...   \n",
       "6    if the tariffs remain in place for any length...   \n",
       "7   in taiwan  businessmen and officials are also ...   \n",
       "8          we are aware of the seriousness of the us    \n",
       "9   threat against japan because it serves as a wa...   \n",
       "10  taiwan had a trade trade surplus of    billion...   \n",
       "11  the surplus helped swell taiwan's foreign exch...   \n",
       "12   we must quickly open our markets  remove trad...   \n",
       "13  retaliation  said paul sheen  chairman of text...   \n",
       "14  a senior official of south korea's trade promo...   \n",
       "15  last year south korea had a trade surplus of  ...   \n",
       "16  in malaysia  trade officers and businessmen sa...   \n",
       "17  in hong kong  where newspapers have alleged ja...   \n",
       "18  but other businessmen said such a short  term ...   \n",
       "19   that is a very short  term view  said lawrenc...   \n",
       "\n",
       "                                              unigram  \\\n",
       "0   [[asian], [exporters], [fear], [damage], [from...   \n",
       "1   [[they], [told], [reuter], [correspondents], [...   \n",
       "2   [[but], [some], [exporters], [said], [that], [...   \n",
       "3   [[the], [us], [has], [said], [it], [will], [im...   \n",
       "4   [[unofficial], [japanese], [estimates], [put],...   \n",
       "5   [[we], [wouldn't], [be], [able], [to], [do], [...   \n",
       "6   [[if], [the], [tariffs], [remain], [in], [plac...   \n",
       "7   [[in], [taiwan], [businessmen], [and], [offici...   \n",
       "8   [[we], [are], [aware], [of], [the], [seriousne...   \n",
       "9   [[threat], [against], [japan], [because], [it]...   \n",
       "10  [[taiwan], [had], [a], [trade], [trade], [surp...   \n",
       "11  [[the], [surplus], [helped], [swell], [taiwan'...   \n",
       "12  [[we], [must], [quickly], [open], [our], [mark...   \n",
       "13  [[retaliation], [said], [paul], [sheen], [chai...   \n",
       "14  [[a], [senior], [official], [of], [south], [ko...   \n",
       "15  [[last], [year], [south], [korea], [had], [a],...   \n",
       "16  [[in], [malaysia], [trade], [officers], [and],...   \n",
       "17  [[in], [hong], [kong], [where], [newspapers], ...   \n",
       "18  [[but], [other], [businessmen], [said], [such]...   \n",
       "19  [[that], [is], [a], [very], [short], [term], [...   \n",
       "\n",
       "                                               bigram  \\\n",
       "0   [[asian, exporters], [exporters, fear], [fear,...   \n",
       "1   [[they, told], [told, reuter], [reuter, corres...   \n",
       "2   [[but, some], [some, exporters], [exporters, s...   \n",
       "3   [[the, us], [us, has], [has, said], [said, it]...   \n",
       "4   [[unofficial, japanese], [japanese, estimates]...   \n",
       "5   [[we, wouldn't], [wouldn't, be], [be, able], [...   \n",
       "6   [[if, the], [the, tariffs], [tariffs, remain],...   \n",
       "7   [[in, taiwan], [taiwan, businessmen], [busines...   \n",
       "8   [[we, are], [are, aware], [aware, of], [of, th...   \n",
       "9   [[threat, against], [against, japan], [japan, ...   \n",
       "10  [[taiwan, had], [had, a], [a, trade], [trade, ...   \n",
       "11  [[the, surplus], [surplus, helped], [helped, s...   \n",
       "12  [[we, must], [must, quickly], [quickly, open],...   \n",
       "13  [[retaliation, said], [said, paul], [paul, she...   \n",
       "14  [[a, senior], [senior, official], [official, o...   \n",
       "15  [[last, year], [year, south], [south, korea], ...   \n",
       "16  [[in, malaysia], [malaysia, trade], [trade, of...   \n",
       "17  [[in, hong], [hong, kong], [kong, where], [whe...   \n",
       "18  [[but, other], [other, businessmen], [business...   \n",
       "19  [[that, is], [is, a], [a, very], [very, short]...   \n",
       "\n",
       "                                              trigram  \n",
       "0   [[asian, exporters, fear], [exporters, fear, d...  \n",
       "1   [[they, told, reuter], [told, reuter, correspo...  \n",
       "2   [[but, some, exporters], [some, exporters, sai...  \n",
       "3   [[the, us, has], [us, has, said], [has, said, ...  \n",
       "4   [[unofficial, japanese, estimates], [japanese,...  \n",
       "5   [[we, wouldn't, be], [wouldn't, be, able], [be...  \n",
       "6   [[if, the, tariffs], [the, tariffs, remain], [...  \n",
       "7   [[in, taiwan, businessmen], [taiwan, businessm...  \n",
       "8   [[we, are, aware], [are, aware, of], [aware, o...  \n",
       "9   [[threat, against, japan], [against, japan, be...  \n",
       "10  [[taiwan, had, a], [had, a, trade], [a, trade,...  \n",
       "11  [[the, surplus, helped], [surplus, helped, swe...  \n",
       "12  [[we, must, quickly], [must, quickly, open], [...  \n",
       "13  [[retaliation, said, paul], [said, paul, sheen...  \n",
       "14  [[a, senior, official], [senior, official, of]...  \n",
       "15  [[last, year, south], [year, south, korea], [s...  \n",
       "16  [[in, malaysia, trade], [malaysia, trade, offi...  \n",
       "17  [[in, hong, kong], [hong, kong, where], [kong,...  \n",
       "18  [[but, other, businessmen], [other, businessme...  \n",
       "19  [[that, is, a], [is, a, very], [a, very, short...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 20 rows of the dataset\n",
    "dataset.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "886861e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"asian exporters fear damage from us  japan rift mounting trade friction between the us  and japan has raised fears among many of asia's exporting nations that the row could inflict far  reaching economic damage  businessmen and officials said \""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample sentence\n",
    "dataset['Sentences'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5508c35c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['asian'],\n",
       " ['exporters'],\n",
       " ['fear'],\n",
       " ['damage'],\n",
       " ['from'],\n",
       " ['us'],\n",
       " ['japan'],\n",
       " ['rift'],\n",
       " ['mounting'],\n",
       " ['trade'],\n",
       " ['friction'],\n",
       " ['between'],\n",
       " ['the'],\n",
       " ['us'],\n",
       " ['and'],\n",
       " ['japan'],\n",
       " ['has'],\n",
       " ['raised'],\n",
       " ['fears'],\n",
       " ['among'],\n",
       " ['many'],\n",
       " ['of'],\n",
       " [\"asia's\"],\n",
       " ['exporting'],\n",
       " ['nations'],\n",
       " ['that'],\n",
       " ['the'],\n",
       " ['row'],\n",
       " ['could'],\n",
       " ['inflict'],\n",
       " ['far'],\n",
       " ['reaching'],\n",
       " ['economic'],\n",
       " ['damage'],\n",
       " ['businessmen'],\n",
       " ['and'],\n",
       " ['officials'],\n",
       " ['said']]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unigram of the sentence\n",
    "dataset['unigram'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "15aef75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['asian', 'exporters'],\n",
       " ['exporters', 'fear'],\n",
       " ['fear', 'damage'],\n",
       " ['damage', 'from'],\n",
       " ['from', 'us'],\n",
       " ['us', 'japan'],\n",
       " ['japan', 'rift'],\n",
       " ['rift', 'mounting'],\n",
       " ['mounting', 'trade'],\n",
       " ['trade', 'friction'],\n",
       " ['friction', 'between'],\n",
       " ['between', 'the'],\n",
       " ['the', 'us'],\n",
       " ['us', 'and'],\n",
       " ['and', 'japan'],\n",
       " ['japan', 'has'],\n",
       " ['has', 'raised'],\n",
       " ['raised', 'fears'],\n",
       " ['fears', 'among'],\n",
       " ['among', 'many'],\n",
       " ['many', 'of'],\n",
       " ['of', \"asia's\"],\n",
       " [\"asia's\", 'exporting'],\n",
       " ['exporting', 'nations'],\n",
       " ['nations', 'that'],\n",
       " ['that', 'the'],\n",
       " ['the', 'row'],\n",
       " ['row', 'could'],\n",
       " ['could', 'inflict'],\n",
       " ['inflict', 'far'],\n",
       " ['far', 'reaching'],\n",
       " ['reaching', 'economic'],\n",
       " ['economic', 'damage'],\n",
       " ['damage', 'businessmen'],\n",
       " ['businessmen', 'and'],\n",
       " ['and', 'officials'],\n",
       " ['officials', 'said']]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bigram of the sentence\n",
    "dataset['bigram'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9c023ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['asian', 'exporters', 'fear'],\n",
       " ['exporters', 'fear', 'damage'],\n",
       " ['fear', 'damage', 'from'],\n",
       " ['damage', 'from', 'us'],\n",
       " ['from', 'us', 'japan'],\n",
       " ['us', 'japan', 'rift'],\n",
       " ['japan', 'rift', 'mounting'],\n",
       " ['rift', 'mounting', 'trade'],\n",
       " ['mounting', 'trade', 'friction'],\n",
       " ['trade', 'friction', 'between'],\n",
       " ['friction', 'between', 'the'],\n",
       " ['between', 'the', 'us'],\n",
       " ['the', 'us', 'and'],\n",
       " ['us', 'and', 'japan'],\n",
       " ['and', 'japan', 'has'],\n",
       " ['japan', 'has', 'raised'],\n",
       " ['has', 'raised', 'fears'],\n",
       " ['raised', 'fears', 'among'],\n",
       " ['fears', 'among', 'many'],\n",
       " ['among', 'many', 'of'],\n",
       " ['many', 'of', \"asia's\"],\n",
       " ['of', \"asia's\", 'exporting'],\n",
       " [\"asia's\", 'exporting', 'nations'],\n",
       " ['exporting', 'nations', 'that'],\n",
       " ['nations', 'that', 'the'],\n",
       " ['that', 'the', 'row'],\n",
       " ['the', 'row', 'could'],\n",
       " ['row', 'could', 'inflict'],\n",
       " ['could', 'inflict', 'far'],\n",
       " ['inflict', 'far', 'reaching'],\n",
       " ['far', 'reaching', 'economic'],\n",
       " ['reaching', 'economic', 'damage'],\n",
       " ['economic', 'damage', 'businessmen'],\n",
       " ['damage', 'businessmen', 'and'],\n",
       " ['businessmen', 'and', 'officials'],\n",
       " ['and', 'officials', 'said']]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trigram of the sentence\n",
    "dataset['trigram'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c956ad2",
   "metadata": {},
   "source": [
    "### 3. Building the N-gram Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4d6d7a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for defining the N-gram model\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Create a placeholder for model\n",
    "model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "# Count frequency of co-occurance  \n",
    "for i in range(dataset.shape[0]):\n",
    "    # for each trigram pair\n",
    "    for w1, w2, w3 in create_trigram(dataset['Sentences'][i]):\n",
    "        # count the occurance of word 3, given word 1 and word 2\n",
    "        model[(w1, w2)][w3] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ddbe623f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('asian', 'exporters'), defaultdict(<function <lambda>.<locals>.<lambda> at 0x00000234F33560D0>, {'fear': 1}))\n",
      "(('exporters', 'fear'), defaultdict(<function <lambda>.<locals>.<lambda> at 0x00000234F3356700>, {'damage': 1}))\n",
      "(('fear', 'damage'), defaultdict(<function <lambda>.<locals>.<lambda> at 0x00000234F33563A0>, {'from': 1}))\n",
      "(('damage', 'from'), defaultdict(<function <lambda>.<locals>.<lambda> at 0x00000234F3356280>, {'us': 1, 'local': 1}))\n",
      "(('from', 'us'), defaultdict(<function <lambda>.<locals>.<lambda> at 0x00000234F3356DC0>, {'japan': 1, 'might': 1, 'ports': 1, 'it': 1, 'plants': 1, \"video's\": 1}))\n"
     ]
    }
   ],
   "source": [
    "# defined model\n",
    "for x in list(model.items())[0:5]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c60f51",
   "metadata": {},
   "source": [
    "### 4. Predicting the next word using N-gram Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aebed614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'us': 5,\n",
       " 'start': 1,\n",
       " 'two': 18,\n",
       " 'employers': 1,\n",
       " 'united': 4,\n",
       " 'demands': 1,\n",
       " 'countries': 1,\n",
       " 'ec': 1,\n",
       " 'dollar': 1,\n",
       " 'white': 1,\n",
       " 'prime': 3,\n",
       " 'report': 2,\n",
       " 'increased': 1,\n",
       " 'secured': 1,\n",
       " 'pork': 1,\n",
       " 'omani': 1,\n",
       " 'group': 1,\n",
       " 'purchase': 1,\n",
       " 'federal': 1,\n",
       " 'first': 1,\n",
       " 'heaviest': 1,\n",
       " 'growth': 1}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict the next word\n",
    "dict(model[\"between\", \"the\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "633ca8a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'japan': 1, 'might': 1, 'ports': 1, 'it': 1, 'plants': 1, \"video's\": 1}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another example\n",
    "dict(model[\"from\", \"us\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4e41a9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'japan': 6,\n",
       " 'lead': 1,\n",
       " 'new': 1,\n",
       " 'japanese': 3,\n",
       " 'rising': 1,\n",
       " 'britain': 2,\n",
       " 'europe': 2,\n",
       " 'west': 3,\n",
       " 'australian': 1,\n",
       " 'world': 1,\n",
       " 'european': 1,\n",
       " 'canada': 2,\n",
       " 'up': 1,\n",
       " 'the': 1,\n",
       " 'hong': 1,\n",
       " 'its': 1,\n",
       " 'other': 2,\n",
       " 'malaysia': 1,\n",
       " 'tight': 1,\n",
       " 'on': 1,\n",
       " 'canadian': 1,\n",
       " 'raise': 1,\n",
       " 'we': 1}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another example\n",
    "dict(model[\"us\", \"and\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e9b691d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"tokyo's\": 1,\n",
       " 'commercial': 1,\n",
       " 'view': 1,\n",
       " 'fluctuations': 2,\n",
       " 'interest': 3,\n",
       " 'impact': 1,\n",
       " 'refers': 1,\n",
       " 'differences': 1,\n",
       " 'discount': 10,\n",
       " 'investment': 1,\n",
       " 'potential': 1,\n",
       " 'given': 1,\n",
       " 'cut': 1,\n",
       " 'money': 1,\n",
       " 'recovery': 1,\n",
       " 'rates': 2,\n",
       " 'rally': 1,\n",
       " 'rate': 2,\n",
       " 'treasury': 1,\n",
       " 'foreign': 1,\n",
       " 'boost': 1}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another example\n",
    "dict(model[\"short\", \"term\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db6f87d",
   "metadata": {},
   "source": [
    "### Probabilistic Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "60688448",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10000/10000 [00:00<00:00, 40699.86it/s]\n"
     ]
    }
   ],
   "source": [
    "# creating the unigram list\n",
    "unigram_dict = {}\n",
    "for i in tqdm(range(dataset.shape[0])):\n",
    "    # add word-count pair to the dictionary\n",
    "    for word in dataset['unigram'][i]:   \n",
    "        # check if the word is already in dictionary \n",
    "        if word[0] in unigram_dict:\n",
    "            # increment count of word by 1 \n",
    "            unigram_dict[word[0]] = unigram_dict[word[0]] + 1\n",
    "        else:\n",
    "            # add the word to dictionary with count 1 \n",
    "            unigram_dict[word[0]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "29cb381c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('asian', 13)\n",
      "('exporters', 49)\n",
      "('fear', 8)\n",
      "('damage', 29)\n",
      "('from', 1369)\n"
     ]
    }
   ],
   "source": [
    "# unigram list\n",
    "for x in list(unigram_dict.items())[0:5]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "18c22c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the overall frequency of words in the corpus\n",
    "counts = Counter(unigram_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ed31d2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('asian', 13)\n",
      "('exporters', 49)\n",
      "('fear', 8)\n",
      "('damage', 29)\n",
      "('from', 1369)\n"
     ]
    }
   ],
   "source": [
    "for x in list(counts.items())[0:5]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dfaab422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13170"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocabulary size\n",
    "total_count = len(unigram_dict)\n",
    "total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5e038fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('asian', 3.281062305721333e-20),\n",
       " ('exporters', 1.23670809984881e-19),\n",
       " ('fear', 2.019115265059282e-20),\n",
       " ('damage', 7.319292835839896e-20),\n",
       " ('from', 3.4552109973326964e-18)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# relative frequencies of each word\n",
    "for word in counts:\n",
    "    counts[word] /= float(total_count)\n",
    "\n",
    "list(counts.items())[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "173afb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's transform the counts to probabilities\n",
    "for w1_w2 in model:\n",
    "    total_count = float(sum(model[w1_w2].values()))\n",
    "    for w3 in model[w1_w2]:\n",
    "        model[w1_w2][w3] /= total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6d3bf40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'us': 0.10204081632653059,\n",
       " 'start': 0.020408163265306117,\n",
       " 'two': 0.36734693877551017,\n",
       " 'employers': 0.020408163265306117,\n",
       " 'united': 0.08163265306122447,\n",
       " 'demands': 0.020408163265306117,\n",
       " 'countries': 0.020408163265306117,\n",
       " 'ec': 0.020408163265306117,\n",
       " 'dollar': 0.020408163265306117,\n",
       " 'white': 0.020408163265306117,\n",
       " 'prime': 0.06122448979591835,\n",
       " 'report': 0.040816326530612235,\n",
       " 'increased': 0.020408163265306117,\n",
       " 'secured': 0.020408163265306117,\n",
       " 'pork': 0.020408163265306117,\n",
       " 'omani': 0.020408163265306117,\n",
       " 'group': 0.020408163265306117,\n",
       " 'purchase': 0.020408163265306117,\n",
       " 'federal': 0.020408163265306117,\n",
       " 'first': 0.020408163265306117,\n",
       " 'heaviest': 0.020408163265306117,\n",
       " 'growth': 0.020408163265306117}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict the next word\n",
    "dict(model[\"between\", \"the\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1fdad57e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'japan': 0.16666666666666663,\n",
       " 'lead': 0.02777777777777777,\n",
       " 'new': 0.02777777777777777,\n",
       " 'japanese': 0.08333333333333331,\n",
       " 'rising': 0.02777777777777777,\n",
       " 'britain': 0.05555555555555554,\n",
       " 'europe': 0.05555555555555554,\n",
       " 'west': 0.08333333333333331,\n",
       " 'australian': 0.02777777777777777,\n",
       " 'world': 0.02777777777777777,\n",
       " 'european': 0.02777777777777777,\n",
       " 'canada': 0.05555555555555554,\n",
       " 'up': 0.02777777777777777,\n",
       " 'the': 0.02777777777777777,\n",
       " 'hong': 0.02777777777777777,\n",
       " 'its': 0.02777777777777777,\n",
       " 'other': 0.05555555555555554,\n",
       " 'malaysia': 0.02777777777777777,\n",
       " 'tight': 0.02777777777777777,\n",
       " 'on': 0.02777777777777777,\n",
       " 'canadian': 0.02777777777777777,\n",
       " 'raise': 0.02777777777777777,\n",
       " 'we': 0.02777777777777777}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another example\n",
    "dict(model[\"us\", \"and\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "843986ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"tokyo's\": 0.02857142857142857,\n",
       " 'commercial': 0.02857142857142857,\n",
       " 'view': 0.02857142857142857,\n",
       " 'fluctuations': 0.05714285714285714,\n",
       " 'interest': 0.08571428571428572,\n",
       " 'impact': 0.02857142857142857,\n",
       " 'refers': 0.02857142857142857,\n",
       " 'differences': 0.02857142857142857,\n",
       " 'discount': 0.2857142857142857,\n",
       " 'investment': 0.02857142857142857,\n",
       " 'potential': 0.02857142857142857,\n",
       " 'given': 0.02857142857142857,\n",
       " 'cut': 0.02857142857142857,\n",
       " 'money': 0.02857142857142857,\n",
       " 'recovery': 0.02857142857142857,\n",
       " 'rates': 0.05714285714285714,\n",
       " 'rally': 0.02857142857142857,\n",
       " 'rate': 0.05714285714285714,\n",
       " 'treasury': 0.02857142857142857,\n",
       " 'foreign': 0.02857142857142857,\n",
       " 'boost': 0.02857142857142857}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another example\n",
    "dict(model[\"short\", \"term\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d34442",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
